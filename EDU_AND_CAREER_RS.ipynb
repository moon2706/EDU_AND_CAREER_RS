{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b0607c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>email</th>\n",
       "      <th>gender</th>\n",
       "      <th>part_time_job</th>\n",
       "      <th>absence_days</th>\n",
       "      <th>extracurricular_activities</th>\n",
       "      <th>weekly_self_study_hours</th>\n",
       "      <th>career_aspiration</th>\n",
       "      <th>math_score</th>\n",
       "      <th>history_score</th>\n",
       "      <th>physics_score</th>\n",
       "      <th>chemistry_score</th>\n",
       "      <th>biology_score</th>\n",
       "      <th>english_score</th>\n",
       "      <th>geography_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Paul</td>\n",
       "      <td>Casey</td>\n",
       "      <td>paul.casey.1@gslingacademy.com</td>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>27</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>73</td>\n",
       "      <td>81</td>\n",
       "      <td>93</td>\n",
       "      <td>97</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Danielle</td>\n",
       "      <td>Sandoval</td>\n",
       "      <td>danielle.sandoval.2@gslingacademy.com</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>47</td>\n",
       "      <td>Doctor</td>\n",
       "      <td>90</td>\n",
       "      <td>86</td>\n",
       "      <td>96</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tina</td>\n",
       "      <td>Andrews</td>\n",
       "      <td>tina.andrews.3@gslingacademy.com</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>Government Officer</td>\n",
       "      <td>81</td>\n",
       "      <td>97</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>65</td>\n",
       "      <td>77</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Tara</td>\n",
       "      <td>Clark</td>\n",
       "      <td>tara.clark.4@gslingacademy.com</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>Artist</td>\n",
       "      <td>71</td>\n",
       "      <td>74</td>\n",
       "      <td>88</td>\n",
       "      <td>80</td>\n",
       "      <td>89</td>\n",
       "      <td>63</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Anthony</td>\n",
       "      <td>Campos</td>\n",
       "      <td>anthony.campos.5@gslingacademy.com</td>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id first_name last_name                                  email  gender  \\\n",
       "0   1       Paul     Casey         paul.casey.1@gslingacademy.com    male   \n",
       "1   2   Danielle  Sandoval  danielle.sandoval.2@gslingacademy.com  female   \n",
       "2   3       Tina   Andrews       tina.andrews.3@gslingacademy.com  female   \n",
       "3   4       Tara     Clark         tara.clark.4@gslingacademy.com  female   \n",
       "4   5    Anthony    Campos     anthony.campos.5@gslingacademy.com    male   \n",
       "\n",
       "   part_time_job  absence_days  extracurricular_activities  \\\n",
       "0          False             3                       False   \n",
       "1          False             2                       False   \n",
       "2          False             9                        True   \n",
       "3          False             5                       False   \n",
       "4          False             5                       False   \n",
       "\n",
       "   weekly_self_study_hours   career_aspiration  math_score  history_score  \\\n",
       "0                       27              Lawyer          73             81   \n",
       "1                       47              Doctor          90             86   \n",
       "2                       13  Government Officer          81             97   \n",
       "3                        3              Artist          71             74   \n",
       "4                       10             Unknown          84             77   \n",
       "\n",
       "   physics_score  chemistry_score  biology_score  english_score  \\\n",
       "0             93               97             63             80   \n",
       "1             96              100             90             88   \n",
       "2             95               96             65             77   \n",
       "3             88               80             89             63   \n",
       "4             65               65             80             74   \n",
       "\n",
       "   geography_score  \n",
       "0               87  \n",
       "1               90  \n",
       "2               94  \n",
       "3               86  \n",
       "4               76  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1=pd.read_csv('student-scores.csv')\n",
    "df=df1.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a5822f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "df.drop(columns=['id', 'first_name', 'last_name', 'email'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8b134ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>part_time_job</th>\n",
       "      <th>absence_days</th>\n",
       "      <th>extracurricular_activities</th>\n",
       "      <th>weekly_self_study_hours</th>\n",
       "      <th>career_aspiration</th>\n",
       "      <th>math_score</th>\n",
       "      <th>history_score</th>\n",
       "      <th>physics_score</th>\n",
       "      <th>chemistry_score</th>\n",
       "      <th>biology_score</th>\n",
       "      <th>english_score</th>\n",
       "      <th>geography_score</th>\n",
       "      <th>total_score</th>\n",
       "      <th>average_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>27</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>73</td>\n",
       "      <td>81</td>\n",
       "      <td>93</td>\n",
       "      <td>97</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "      <td>574</td>\n",
       "      <td>82.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>47</td>\n",
       "      <td>Doctor</td>\n",
       "      <td>90</td>\n",
       "      <td>86</td>\n",
       "      <td>96</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>90</td>\n",
       "      <td>640</td>\n",
       "      <td>91.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>Government Officer</td>\n",
       "      <td>81</td>\n",
       "      <td>97</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>65</td>\n",
       "      <td>77</td>\n",
       "      <td>94</td>\n",
       "      <td>605</td>\n",
       "      <td>86.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>Artist</td>\n",
       "      <td>71</td>\n",
       "      <td>74</td>\n",
       "      <td>88</td>\n",
       "      <td>80</td>\n",
       "      <td>89</td>\n",
       "      <td>63</td>\n",
       "      <td>86</td>\n",
       "      <td>551</td>\n",
       "      <td>78.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "      <td>521</td>\n",
       "      <td>74.428571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  part_time_job  absence_days  extracurricular_activities  \\\n",
       "0    male          False             3                       False   \n",
       "1  female          False             2                       False   \n",
       "2  female          False             9                        True   \n",
       "3  female          False             5                       False   \n",
       "4    male          False             5                       False   \n",
       "\n",
       "   weekly_self_study_hours   career_aspiration  math_score  history_score  \\\n",
       "0                       27              Lawyer          73             81   \n",
       "1                       47              Doctor          90             86   \n",
       "2                       13  Government Officer          81             97   \n",
       "3                        3              Artist          71             74   \n",
       "4                       10             Unknown          84             77   \n",
       "\n",
       "   physics_score  chemistry_score  biology_score  english_score  \\\n",
       "0             93               97             63             80   \n",
       "1             96              100             90             88   \n",
       "2             95               96             65             77   \n",
       "3             88               80             89             63   \n",
       "4             65               65             80             74   \n",
       "\n",
       "   geography_score  total_score  average_score  \n",
       "0               87          574      82.000000  \n",
       "1               90          640      91.428571  \n",
       "2               94          605      86.428571  \n",
       "3               86          551      78.714286  \n",
       "4               76          521      74.428571  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['total_score']=df['math_score']+df['history_score']+df['physics_score']+df['chemistry_score']+df['biology_score']+df['english_score']+df['geography_score']\n",
    "df['average_score']=df['total_score']/7\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "51e2a302",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_map={'male':'0','female':'1'}\n",
    "part_time_job_map={False:'0',True:'1'}\n",
    "extracurricular_activities_map={False:'0',True:'1'}\n",
    "career_aspiration_map={'Lawyer':0, 'Doctor':1, 'Government Officer':2, 'Artist':3, 'Unknown':4,\n",
    "       'Software Engineer':5, 'Teacher':6, 'Business Owner':7, 'Scientist':8,\n",
    "       'Banker':9, 'Writer':10, 'Accountant':11, 'Designer':12,\n",
    "       'Construction Engineer':13, 'Game Developer':14, 'Stock Investor':15,\n",
    "       'Real Estate Developer':16}\n",
    "df['gender']=df['gender'].map(gender_map)\n",
    "df['part_time_job']=df['part_time_job'].map(part_time_job_map)\n",
    "df['extracurricular_activities']=df['extracurricular_activities'].map(extracurricular_activities_map)\n",
    "df['career_aspiration']=df['career_aspiration'].map(career_aspiration_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9e044599",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['career_aspiration'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f616a9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>part_time_job</th>\n",
       "      <th>absence_days</th>\n",
       "      <th>extracurricular_activities</th>\n",
       "      <th>weekly_self_study_hours</th>\n",
       "      <th>career_aspiration</th>\n",
       "      <th>math_score</th>\n",
       "      <th>history_score</th>\n",
       "      <th>physics_score</th>\n",
       "      <th>chemistry_score</th>\n",
       "      <th>biology_score</th>\n",
       "      <th>english_score</th>\n",
       "      <th>geography_score</th>\n",
       "      <th>total_score</th>\n",
       "      <th>average_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>81</td>\n",
       "      <td>93</td>\n",
       "      <td>97</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "      <td>574</td>\n",
       "      <td>82.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>86</td>\n",
       "      <td>96</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>90</td>\n",
       "      <td>640</td>\n",
       "      <td>91.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>97</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>65</td>\n",
       "      <td>77</td>\n",
       "      <td>94</td>\n",
       "      <td>605</td>\n",
       "      <td>86.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>71</td>\n",
       "      <td>74</td>\n",
       "      <td>88</td>\n",
       "      <td>80</td>\n",
       "      <td>89</td>\n",
       "      <td>63</td>\n",
       "      <td>86</td>\n",
       "      <td>551</td>\n",
       "      <td>78.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "      <td>521</td>\n",
       "      <td>74.428571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender part_time_job  absence_days extracurricular_activities  \\\n",
       "0      0             0             3                          0   \n",
       "1      1             0             2                          0   \n",
       "2      1             0             9                          1   \n",
       "3      1             0             5                          0   \n",
       "4      0             0             5                          0   \n",
       "\n",
       "   weekly_self_study_hours  career_aspiration  math_score  history_score  \\\n",
       "0                       27                  0          73             81   \n",
       "1                       47                  1          90             86   \n",
       "2                       13                  2          81             97   \n",
       "3                        3                  3          71             74   \n",
       "4                       10                  4          84             77   \n",
       "\n",
       "   physics_score  chemistry_score  biology_score  english_score  \\\n",
       "0             93               97             63             80   \n",
       "1             96              100             90             88   \n",
       "2             95               96             65             77   \n",
       "3             88               80             89             63   \n",
       "4             65               65             80             74   \n",
       "\n",
       "   geography_score  total_score  average_score  \n",
       "0               87          574      82.000000  \n",
       "1               90          640      91.428571  \n",
       "2               94          605      86.428571  \n",
       "3               86          551      78.714286  \n",
       "4               76          521      74.428571  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8c4f3603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['career_aspiration'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c261f6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5     315\n",
       "7     309\n",
       "4     223\n",
       "9     169\n",
       "0     138\n",
       "11    126\n",
       "1     119\n",
       "16     83\n",
       "15     73\n",
       "13     68\n",
       "3      67\n",
       "14     63\n",
       "2      61\n",
       "6      59\n",
       "12     56\n",
       "8      39\n",
       "10     32\n",
       "Name: career_aspiration, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['career_aspiration'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f7c974db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote=SMOTE(random_state=42)\n",
    "x=df.drop('career_aspiration',axis=1)\n",
    "y=df['career_aspiration']\n",
    "\n",
    "x_resampled,y_resampled=smote.fit_resample(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "53f4c6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x_resampled,y_resampled,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "850576f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4284, 14)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "79e674d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "x_train_scaled=scaler.fit_transform(x_train)\n",
    "x_test_scaled=scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f3885a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4284, 14)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02321f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d64c537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "01f539b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8f25f59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "model:  Logistic Regression\n",
      "accuracy  0.4995331465919701\n",
      "classification_report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.46      0.45        68\n",
      "           1       0.56      0.67      0.61        72\n",
      "           2       0.44      0.40      0.42        57\n",
      "           3       0.53      0.59      0.56        58\n",
      "           4       0.31      0.17      0.22        66\n",
      "           5       0.33      0.28      0.30        76\n",
      "           6       0.60      0.85      0.70        71\n",
      "           7       0.79      0.89      0.84        61\n",
      "           8       0.44      0.57      0.50        53\n",
      "           9       0.19      0.08      0.11        61\n",
      "          10       0.54      0.73      0.62        63\n",
      "          11       0.45      0.47      0.46        53\n",
      "          12       0.35      0.21      0.26        68\n",
      "          13       0.47      0.75      0.57        55\n",
      "          14       0.61      0.95      0.74        57\n",
      "          15       0.46      0.27      0.34        63\n",
      "          16       0.47      0.30      0.37        69\n",
      "\n",
      "    accuracy                           0.50      1071\n",
      "   macro avg       0.47      0.51      0.47      1071\n",
      "weighted avg       0.47      0.50      0.47      1071\n",
      "\n",
      "confusion_matrix\n",
      "  [[31  4  0  0  0  5  0  0  3  2  9  5  0  9  0  0  0]\n",
      " [ 3 48  0  0  0  5  0  0 13  0  0  0  1  2  0  0  0]\n",
      " [ 0  0 23  3  2  1  8  0  0  0  3  0  7  2  2  1  5]\n",
      " [ 0  0  2 34  0  0  1  2  0  0  0  0  0  0 10  0  9]\n",
      " [ 4  4  7  3 11  9  5  1  4  3  0  4  4  2  1  1  3]\n",
      " [ 5  9  0  0  1 21  1  0  4  7  1  6  1 16  0  4  0]\n",
      " [ 0  0  0  0  0  1 60  0  0  1  4  0  3  0  1  0  1]\n",
      " [ 0  0  0  1  0  0  0 54  0  0  0  0  0  0  4  0  2]\n",
      " [ 4 11  0  0  0  0  0  0 30  0  7  0  0  1  0  0  0]\n",
      " [11  0  2  0  3  9  7  0  2  5  4  8  5  3  0  2  0]\n",
      " [ 7  2  0  0  1  0  3  0  2  1 46  0  0  0  1  0  0]\n",
      " [ 0  1  1  0  6  5  2  0  4  2  0 25  0  4  0  3  0]\n",
      " [ 1  1  6  2  5  2  8  2  4  1  4  0 14  2  8  6  2]\n",
      " [ 1  3  0  0  2  0  0  0  1  1  3  2  0 41  0  1  0]\n",
      " [ 0  0  0  2  0  0  0  0  0  0  0  0  0  0 54  0  1]\n",
      " [ 4  2  4  0  4  5  0  3  1  3  3  5  4  6  1 17  1]\n",
      " [ 0  0  7 19  0  0  5  6  0  0  1  0  1  0  7  2 21]]\n",
      "==================================================\n",
      "model:  support vector classifier\n",
      "accuracy  0.7021475256769374\n",
      "classification_report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.71      0.65        68\n",
      "           1       0.64      0.90      0.75        72\n",
      "           2       0.67      0.84      0.74        57\n",
      "           3       0.76      0.90      0.83        58\n",
      "           4       0.56      0.30      0.39        66\n",
      "           5       0.46      0.34      0.39        76\n",
      "           6       0.79      0.94      0.86        71\n",
      "           7       0.89      0.92      0.90        61\n",
      "           8       0.70      0.87      0.77        53\n",
      "           9       0.51      0.41      0.45        61\n",
      "          10       0.83      0.86      0.84        63\n",
      "          11       0.68      0.49      0.57        53\n",
      "          12       0.78      0.63      0.70        68\n",
      "          13       0.64      0.84      0.72        55\n",
      "          14       0.82      0.96      0.89        57\n",
      "          15       0.83      0.60      0.70        63\n",
      "          16       0.73      0.54      0.62        69\n",
      "\n",
      "    accuracy                           0.70      1071\n",
      "   macro avg       0.70      0.71      0.69      1071\n",
      "weighted avg       0.70      0.70      0.69      1071\n",
      "\n",
      "confusion_matrix\n",
      "  [[48  5  0  0  0  3  0  0  1  3  6  1  0  1  0  0  0]\n",
      " [ 1 65  0  0  0  1  0  0  5  0  0  0  0  0  0  0  0]\n",
      " [ 0  1 48  1  1  0  1  0  0  0  0  0  2  0  0  0  3]\n",
      " [ 0  0  1 52  0  0  0  1  0  0  0  0  0  0  2  0  2]\n",
      " [ 3  6  6  0 20  8  4  1  2  3  2  1  4  2  2  2  0]\n",
      " [ 5  7  1  0  0 26  2  1  4 10  1  3  2 13  0  1  0]\n",
      " [ 0  0  0  0  0  0 67  0  0  1  0  0  1  0  0  1  1]\n",
      " [ 0  0  0  1  0  0  0 56  0  0  0  0  0  0  2  0  2]\n",
      " [ 2  5  0  0  0  0  0  0 46  0  0  0  0  0  0  0  0]\n",
      " [ 9  2  2  0  2  3  6  1  0 25  1  1  3  3  0  3  0]\n",
      " [ 2  2  2  0  2  0  0  0  1  0 54  0  0  0  0  0  0]\n",
      " [ 1  3  1  0  4  7  0  1  2  3  1 26  0  3  0  1  0]\n",
      " [ 2  1  3  1  3  2  3  0  3  1  0  1 43  1  1  0  3]\n",
      " [ 1  3  0  0  0  1  0  0  2  1  0  1  0 46  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 55  0  2]\n",
      " [ 6  2  2  0  1  3  0  0  0  2  0  4  0  3  1 38  1]\n",
      " [ 0  0  6 13  3  2  2  2  0  0  0  0  0  0  4  0 37]]\n",
      "==================================================\n",
      "model:  Random Forest Classifier\n",
      "accuracy  0.8263305322128851\n",
      "classification_report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83        68\n",
      "           1       0.75      0.97      0.85        72\n",
      "           2       0.77      0.98      0.86        57\n",
      "           3       0.83      0.95      0.89        58\n",
      "           4       0.77      0.45      0.57        66\n",
      "           5       0.61      0.36      0.45        76\n",
      "           6       0.95      1.00      0.97        71\n",
      "           7       0.95      0.90      0.92        61\n",
      "           8       0.75      0.87      0.81        53\n",
      "           9       0.73      0.67      0.70        61\n",
      "          10       0.90      0.98      0.94        63\n",
      "          11       0.83      0.75      0.79        53\n",
      "          12       0.91      0.85      0.88        68\n",
      "          13       0.76      0.95      0.85        55\n",
      "          14       0.89      1.00      0.94        57\n",
      "          15       0.81      0.83      0.82        63\n",
      "          16       0.96      0.80      0.87        69\n",
      "\n",
      "    accuracy                           0.83      1071\n",
      "   macro avg       0.82      0.83      0.82      1071\n",
      "weighted avg       0.82      0.83      0.82      1071\n",
      "\n",
      "confusion_matrix\n",
      "  [[58  2  0  0  1  0  0  0  1  2  2  1  0  1  0  0  0]\n",
      " [ 0 70  0  0  0  0  0  0  1  0  0  0  1  0  0  0  0]\n",
      " [ 0  0 56  0  0  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 55  0  0  0  1  0  0  0  0  0  0  2  0  0]\n",
      " [ 4  2  6  0 30  7  1  0  1  1  1  1  3  2  1  5  1]\n",
      " [ 4  8  0  0  2 27  1  0  6 10  0  2  0 11  0  5  0]\n",
      " [ 0  0  0  0  0  0 71  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  3  0  0  0 55  0  0  0  0  0  0  2  0  1]\n",
      " [ 0  6  0  0  0  0  0  0 46  0  0  0  0  1  0  0  0]\n",
      " [ 3  1  2  0  0  5  1  0  2 41  3  0  2  0  0  1  0]\n",
      " [ 0  0  1  0  0  0  0  0  0  0 62  0  0  0  0  0  0]\n",
      " [ 1  2  0  0  4  2  0  0  2  1  0 40  0  1  0  0  0]\n",
      " [ 0  1  2  0  1  2  0  0  0  0  1  0 58  0  2  1  0]\n",
      " [ 0  0  1  0  0  0  0  0  2  0  0  0  0 52  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 57  0  0]\n",
      " [ 2  0  2  0  1  1  0  0  0  1  0  4  0  0  0 52  0]\n",
      " [ 0  1  3  8  0  0  0  2  0  0  0  0  0  0  0  0 55]]\n",
      "==================================================\n",
      "model:  K Nearest Neighbors\n",
      "accuracy  0.7366946778711485\n",
      "classification_report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.72      0.69        68\n",
      "           1       0.81      0.78      0.79        72\n",
      "           2       0.72      0.98      0.83        57\n",
      "           3       0.73      0.91      0.81        58\n",
      "           4       0.37      0.20      0.26        66\n",
      "           5       0.45      0.13      0.20        76\n",
      "           6       0.82      0.96      0.88        71\n",
      "           7       0.91      0.69      0.79        61\n",
      "           8       0.69      1.00      0.82        53\n",
      "           9       0.55      0.44      0.49        61\n",
      "          10       0.79      0.97      0.87        63\n",
      "          11       0.66      0.66      0.66        53\n",
      "          12       0.79      0.93      0.85        68\n",
      "          13       0.68      0.82      0.74        55\n",
      "          14       0.89      0.98      0.93        57\n",
      "          15       0.74      0.78      0.76        63\n",
      "          16       0.90      0.77      0.83        69\n",
      "\n",
      "    accuracy                           0.74      1071\n",
      "   macro avg       0.72      0.75      0.72      1071\n",
      "weighted avg       0.71      0.74      0.71      1071\n",
      "\n",
      "confusion_matrix\n",
      "  [[49  1  0  0  1  1  0  0  3  5  3  0  0  2  0  3  0]\n",
      " [ 3 56  0  0  0  1  0  0 10  0  0  0  0  1  0  1  0]\n",
      " [ 0  0 56  0  0  0  0  0  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  0  0 53  0  0  1  1  0  1  0  0  0  0  1  0  1]\n",
      " [ 5  3  4  2 13  5  4  1  3  4  3  3  6  3  2  4  1]\n",
      " [ 8  7  1  0  9 10  2  1  3 10  3  3  4  9  0  6  0]\n",
      " [ 0  0  0  2  0  0 68  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  2  2  5  0  1 42  0  0  0  1  3  1  2  0  2]\n",
      " [ 0  0  0  0  0  0  0  0 53  0  0  0  0  0  0  0  0]\n",
      " [ 4  1  3  1  2  1  5  1  0 27  4  5  3  0  0  3  1]\n",
      " [ 0  0  2  0  0  0  0  0  0  0 61  0  0  0  0  0  0]\n",
      " [ 2  1  3  1  1  3  0  0  2  0  2 35  1  1  0  0  1]\n",
      " [ 0  0  0  1  0  0  1  0  0  0  1  2 63  0  0  0  0]\n",
      " [ 1  0  1  1  2  1  0  0  2  1  0  1  0 45  0  0  0]\n",
      " [ 0  0  1  0  0  0  0  0  0  0  0  0  0  0 56  0  0]\n",
      " [ 3  0  0  3  0  0  0  0  1  0  0  3  0  4  0 49  0]\n",
      " [ 0  0  5  7  2  0  1  0  0  0  0  0  0  0  1  0 53]]\n",
      "==================================================\n",
      "model:  Decision Tree Classifier\n",
      "accuracy  0.6479925303454716\n",
      "classification_report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.50      0.56        68\n",
      "           1       0.69      0.79      0.74        72\n",
      "           2       0.68      0.72      0.70        57\n",
      "           3       0.80      0.71      0.75        58\n",
      "           4       0.40      0.35      0.37        66\n",
      "           5       0.41      0.26      0.32        76\n",
      "           6       0.83      0.87      0.85        71\n",
      "           7       0.94      0.74      0.83        61\n",
      "           8       0.84      0.72      0.78        53\n",
      "           9       0.44      0.46      0.45        61\n",
      "          10       0.76      0.87      0.81        63\n",
      "          11       0.53      0.58      0.55        53\n",
      "          12       0.54      0.71      0.61        68\n",
      "          13       0.70      0.82      0.76        55\n",
      "          14       0.79      0.84      0.81        57\n",
      "          15       0.50      0.49      0.50        63\n",
      "          16       0.61      0.68      0.64        69\n",
      "\n",
      "    accuracy                           0.65      1071\n",
      "   macro avg       0.65      0.65      0.65      1071\n",
      "weighted avg       0.65      0.65      0.64      1071\n",
      "\n",
      "confusion_matrix\n",
      "  [[34  2  0  0  2 11  0  0  1  2  9  1  1  3  0  2  0]\n",
      " [ 0 57  0  0  1  2  0  0  1  1  0  5  2  1  0  2  0]\n",
      " [ 0  0 41  0  1  1  0  1  0  2  0  0  3  1  0  1  6]\n",
      " [ 0  0  0 41  1  0  0  0  0  0  0  0  3  0  5  0  8]\n",
      " [ 3  4  4  1 23  3  3  0  1  5  1  2  5  1  1  3  6]\n",
      " [ 3  7  0  0  8 20  2  0  3 11  1  4  6  7  0  4  0]\n",
      " [ 0  0  2  0  2  1 62  0  0  1  1  0  2  0  0  0  0]\n",
      " [ 0  0  1  2  4  0  0 45  0  0  0  0  0  0  3  0  6]\n",
      " [ 1  6  0  0  0  1  0  0 38  2  2  3  0  0  0  0  0]\n",
      " [11  0  1  0  2  0  3  0  0 28  2  4  1  0  0  9  0]\n",
      " [ 1  1  0  0  1  0  0  0  0  1 55  1  2  1  0  0  0]\n",
      " [ 0  2  0  0  3  3  2  0  1  3  0 31  4  2  0  2  0]\n",
      " [ 0  0  2  0  2  1  1  0  0  3  1  1 48  2  3  3  1]\n",
      " [ 0  0  1  0  0  3  0  0  0  1  0  2  0 45  0  3  0]\n",
      " [ 0  0  2  0  1  0  0  0  0  0  0  0  5  0 48  0  1]\n",
      " [ 1  4  3  0  4  2  2  0  0  4  0  5  4  1  0 31  2]\n",
      " [ 0  0  3  7  3  1  0  2  0  0  0  0  3  0  1  2 47]]\n",
      "==================================================\n",
      "model:  Gaussian NB\n",
      "accuracy  0.446311858076564\n",
      "classification_report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.57      0.55        68\n",
      "           1       0.50      0.83      0.62        72\n",
      "           2       0.30      0.47      0.37        57\n",
      "           3       0.50      0.40      0.44        58\n",
      "           4       0.19      0.15      0.17        66\n",
      "           5       0.40      0.26      0.32        76\n",
      "           6       0.00      0.00      0.00        71\n",
      "           7       0.86      0.92      0.89        61\n",
      "           8       0.68      0.79      0.73        53\n",
      "           9       0.16      0.13      0.14        61\n",
      "          10       0.52      0.67      0.58        63\n",
      "          11       0.43      0.57      0.49        53\n",
      "          12       0.21      0.26      0.23        68\n",
      "          13       0.00      0.00      0.00        55\n",
      "          14       0.67      0.93      0.78        57\n",
      "          15       0.26      0.29      0.27        63\n",
      "          16       0.42      0.46      0.44        69\n",
      "\n",
      "    accuracy                           0.45      1071\n",
      "   macro avg       0.39      0.45      0.41      1071\n",
      "weighted avg       0.39      0.45      0.41      1071\n",
      "\n",
      "confusion_matrix\n",
      "  [[39  7  0  0  2  2  0  0  3  2  9  3  0  0  0  1  0]\n",
      " [ 0 60  0  0  0  5  0  0  4  0  0  0  3  0  0  0  0]\n",
      " [ 0  1 27  4  5  0  0  0  0  0  1  0  9  0  0  3  7]\n",
      " [ 0  1  0 23  0  0  0  2  0  0  0  0  0  0 15  0 17]\n",
      " [ 6  6  5  3 10  3  0  0  2  4  3  4  8  0  0  5  7]\n",
      " [ 9  8  0  0  1 20  0  0  4  9  2 11  3  0  0  9  0]\n",
      " [ 0  1 27  0 10  0  0  0  0  4  8  1 16  0  0  1  3]\n",
      " [ 0  0  0  1  0  0  0 56  0  0  0  0  0  0  2  0  2]\n",
      " [ 0  6  0  0  0  0  0  0 42  2  0  0  1  0  0  2  0]\n",
      " [ 9  2  5  0  2  5  0  0  3  8  9  7  7  0  0  4  0]\n",
      " [ 8  6  0  0  3  0  0  0  0  1 42  0  3  0  0  0  0]\n",
      " [ 0  5  0  0  5  2  0  0  1  2  0 30  4  0  0  4  0]\n",
      " [ 2  8 15  1  3  1  0  1  1  1  4  0 18  0  5  3  5]\n",
      " [ 0  7  0  0  2  2  0  0  2 10  2  6  8  0  0 16  0]\n",
      " [ 0  0  0  2  0  0  0  0  0  0  0  0  0  0 53  0  2]\n",
      " [ 1  2  1  0  8 10  0  0  0  6  1  8  7  0  0 18  1]\n",
      " [ 0  1 10 12  1  0  0  6  0  1  0  0  0  0  4  2 32]]\n",
      "==================================================\n",
      "model:  Ada Boost Classifier\n",
      "accuracy  0.23436041083099907\n",
      "classification_report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        68\n",
      "           1       1.00      0.60      0.75        72\n",
      "           2       0.28      0.56      0.37        57\n",
      "           3       0.00      0.00      0.00        58\n",
      "           4       0.00      0.00      0.00        66\n",
      "           5       0.00      0.00      0.00        76\n",
      "           6       0.29      0.79      0.42        71\n",
      "           7       0.00      0.00      0.00        61\n",
      "           8       0.17      1.00      0.28        53\n",
      "           9       0.00      0.00      0.00        61\n",
      "          10       0.17      0.41      0.24        63\n",
      "          11       0.00      0.00      0.00        53\n",
      "          12       0.00      0.00      0.00        68\n",
      "          13       0.00      0.00      0.00        55\n",
      "          14       0.00      0.00      0.00        57\n",
      "          15       0.00      0.00      0.00        63\n",
      "          16       0.17      0.59      0.27        69\n",
      "\n",
      "    accuracy                           0.23      1071\n",
      "   macro avg       0.12      0.23      0.14      1071\n",
      "weighted avg       0.13      0.23      0.14      1071\n",
      "\n",
      "confusion_matrix\n",
      "  [[ 0  0  0  0  0  0  0  0 65  0  3  0  0  0  0  0  0]\n",
      " [ 0 43  0  0  0  0  0  0 17  0 12  0  0  0  0  0  0]\n",
      " [ 0  0 32  0  0  0 15  0  0  0  0  0  0  0  0  0 10]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 58]\n",
      " [ 0  0 14  0  0  0  9  0 27  0 11  0  0  0  0  0  5]\n",
      " [ 0  0  0  0  0  0 10  0 42  0 24  0  0  0  0  0  0]\n",
      " [ 0  0 14  0  0  0 56  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 61]\n",
      " [ 0  0  0  0  0  0  0  0 53  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  3  0  0  0 18  0 22  0 18  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  8  0 29  0 26  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 15  0 17  0 21  0  0  0  0  0  0]\n",
      " [ 0  0 16  0  0  0 24  0 10  0 10  0  0  0  0  0  8]\n",
      " [ 0  0  1  0  0  0 25  0 13  0 16  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 57]\n",
      " [ 0  0  8  0  0  0 15  0 25  0 15  0  0  0  0  0  0]\n",
      " [ 0  0 28  0  0  0  0  0  0  0  0  0  0  0  0  0 41]]\n",
      "==================================================\n",
      "model:  Gradient Boosting Classifier\n",
      "accuracy  0.6498599439775911\n",
      "classification_report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.69      0.66        68\n",
      "           1       0.74      0.94      0.83        72\n",
      "           2       0.52      0.89      0.66        57\n",
      "           3       0.79      0.90      0.84        58\n",
      "           4       0.38      0.20      0.26        66\n",
      "           5       0.50      0.20      0.28        76\n",
      "           6       0.00      0.00      0.00        71\n",
      "           7       0.98      0.89      0.93        61\n",
      "           8       0.65      0.74      0.69        53\n",
      "           9       0.31      0.48      0.37        61\n",
      "          10       0.75      0.95      0.84        63\n",
      "          11       0.59      0.62      0.61        53\n",
      "          12       0.64      0.69      0.66        68\n",
      "          13       0.68      0.89      0.77        55\n",
      "          14       0.86      0.96      0.91        57\n",
      "          15       0.71      0.54      0.61        63\n",
      "          16       0.69      0.72      0.71        69\n",
      "\n",
      "    accuracy                           0.65      1071\n",
      "   macro avg       0.61      0.66      0.63      1071\n",
      "weighted avg       0.61      0.65      0.61      1071\n",
      "\n",
      "confusion_matrix\n",
      "  [[47  3  0  0  1  1  0  0  1  7  5  2  0  1  0  0  0]\n",
      " [ 0 68  0  0  0  0  0  0  2  0  0  0  0  2  0  0  0]\n",
      " [ 0  0 51  1  0  0  0  0  0  0  0  1  1  0  0  0  3]\n",
      " [ 0  0  0 52  1  0  0  1  0  0  0  0  0  0  1  0  3]\n",
      " [ 5  1 11  1 13  6  0  0  2  6  2  3  4  3  1  3  5]\n",
      " [11  2  0  0  2 15  0  0  6 19  0  2  3 12  0  4  0]\n",
      " [ 0  0 19  0 11  0  0  0  0 20  4  2 10  0  0  0  5]\n",
      " [ 0  0  0  3  0  0  0 54  0  0  0  0  0  0  3  0  1]\n",
      " [ 0 11  0  0  0  0  0  0 39  0  2  0  1  0  0  0  0]\n",
      " [ 4  0  3  0  2  1  0  0  4 29  6  2  5  2  0  3  0]\n",
      " [ 3  0  0  0  0  0  0  0  0  0 60  0  0  0  0  0  0]\n",
      " [ 1  3  2  0  0  1  0  0  3  6  0 33  0  2  0  2  0]\n",
      " [ 0  2  2  0  0  2  0  0  1  3  1  1 47  1  3  2  3]\n",
      " [ 1  1  2  0  0  0  0  0  2  0  0  0  0 49  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0 55  0  1]\n",
      " [ 3  1  2  0  2  4  0  0  0  5  0 10  1  0  0 34  1]\n",
      " [ 0  0  6  9  2  0  0  0  0  0  0  0  1  0  1  0 50]]\n",
      "==================================================\n",
      "model:  XGBoost Classifier\n",
      "accuracy  0.7871148459383753\n",
      "classification_report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74        68\n",
      "           1       0.76      0.92      0.83        72\n",
      "           2       0.72      0.89      0.80        57\n",
      "           3       0.78      0.93      0.85        58\n",
      "           4       0.81      0.39      0.53        66\n",
      "           5       0.75      0.20      0.31        76\n",
      "           6       0.91      0.99      0.95        71\n",
      "           7       0.93      0.92      0.93        61\n",
      "           8       0.77      0.75      0.76        53\n",
      "           9       0.55      0.69      0.61        61\n",
      "          10       0.91      0.95      0.93        63\n",
      "          11       0.73      0.75      0.74        53\n",
      "          12       0.83      0.78      0.80        68\n",
      "          13       0.72      0.93      0.81        55\n",
      "          14       0.88      1.00      0.93        57\n",
      "          15       0.79      0.84      0.82        63\n",
      "          16       0.86      0.83      0.84        69\n",
      "\n",
      "    accuracy                           0.79      1071\n",
      "   macro avg       0.79      0.80      0.78      1071\n",
      "weighted avg       0.79      0.79      0.77      1071\n",
      "\n",
      "confusion_matrix\n",
      "  [[52  4  0  0  1  0  0  0  1  7  1  1  0  1  0  0  0]\n",
      " [ 1 66  0  0  1  0  0  0  1  1  0  0  1  1  0  0  0]\n",
      " [ 0  0 51  4  0  0  0  0  0  0  0  1  0  0  0  0  1]\n",
      " [ 0  0  0 54  1  0  0  1  0  0  0  0  0  0  1  0  1]\n",
      " [ 4  2  7  1 26  3  1  0  1  4  2  3  4  1  1  3  3]\n",
      " [ 7  4  0  0  1 15  2  0  4 15  0  4  1 15  0  8  0]\n",
      " [ 0  0  0  0  0  0 70  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  2  0  0  0 56  0  0  0  0  0  0  2  0  1]\n",
      " [ 0  7  0  0  0  0  0  0 40  1  3  0  2  0  0  0  0]\n",
      " [ 4  0  4  0  2  0  1  0  2 42  0  2  2  0  0  2  0]\n",
      " [ 1  0  2  0  0  0  0  0  0  0 60  0  0  0  0  0  0]\n",
      " [ 1  2  0  0  0  2  3  0  1  1  0 40  0  2  0  1  0]\n",
      " [ 0  1  1  2  0  0  0  0  1  2  0  1 53  0  4  0  3]\n",
      " [ 0  0  2  0  0  0  0  0  1  1  0  0  0 51  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 57  0  0]\n",
      " [ 2  1  2  0  0  0  0  0  0  2  0  3  0  0  0 53  0]\n",
      " [ 0  0  2  6  0  0  0  3  0  0  0  0  1  0  0  0 57]]\n"
     ]
    }
   ],
   "source": [
    "models={\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'support vector classifier':SVC(),\n",
    "    'Random Forest Classifier':RandomForestClassifier(),\n",
    "    'K Nearest Neighbors':KNeighborsClassifier(),\n",
    "    'Decision Tree Classifier':DecisionTreeClassifier(),\n",
    "    'Gaussian NB':GaussianNB(),\n",
    "    'Ada Boost Classifier':AdaBoostClassifier(),\n",
    "    'Gradient Boosting Classifier':GradientBoostingClassifier(),\n",
    "    'XGBoost Classifier':XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),\n",
    "}\n",
    "\n",
    "for name,model in models.items():\n",
    "    print('='*50)\n",
    "    print('model: ',name)\n",
    "    model.fit(x_train_scaled,y_train)\n",
    "    y_pred=model.predict(x_test_scaled)\n",
    "    \n",
    "    accuracy=accuracy_score(y_test,y_pred)\n",
    "    classification_rep=classification_report(y_test,y_pred)\n",
    "    conf_matrix=confusion_matrix(y_test,y_pred)\n",
    "    \n",
    "    print('accuracy ',accuracy)\n",
    "    print('classification_report\\n ',classification_rep)                            \n",
    "    print('confusion_matrix\\n ',conf_matrix)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7641f4e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "849aae79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy  0.8319327731092437\n",
      "classification_report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83        68\n",
      "           1       0.76      1.00      0.86        72\n",
      "           2       0.76      0.98      0.85        57\n",
      "           3       0.87      0.93      0.90        58\n",
      "           4       0.79      0.45      0.58        66\n",
      "           5       0.59      0.32      0.41        76\n",
      "           6       0.93      1.00      0.97        71\n",
      "           7       0.98      0.92      0.95        61\n",
      "           8       0.71      0.89      0.79        53\n",
      "           9       0.71      0.69      0.70        61\n",
      "          10       0.94      0.98      0.96        63\n",
      "          11       0.82      0.77      0.80        53\n",
      "          12       0.92      0.87      0.89        68\n",
      "          13       0.79      0.95      0.86        55\n",
      "          14       0.89      1.00      0.94        57\n",
      "          15       0.93      0.84      0.88        63\n",
      "          16       0.92      0.81      0.86        69\n",
      "\n",
      "    accuracy                           0.83      1071\n",
      "   macro avg       0.83      0.84      0.83      1071\n",
      "weighted avg       0.83      0.83      0.82      1071\n",
      "\n",
      "confusion_matrix\n",
      "  [[59  2  0  0  1  1  0  0  2  0  1  0  0  2  0  0  0]\n",
      " [ 0 72  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 56  0  0  0  0  0  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  0  0 54  0  0  0  1  0  0  0  0  0  0  2  0  1]\n",
      " [ 3  2  7  0 30  7  2  0  2  3  1  3  2  1  1  1  1]\n",
      " [ 5  7  0  0  3 24  1  0  8 12  0  2  1 10  0  3  0]\n",
      " [ 0  0  0  0  0  0 71  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  1  0  0 56  0  0  0  0  0  0  2  0  1]\n",
      " [ 0  6  0  0  0  0  0  0 47  0  0  0  0  0  0  0  0]\n",
      " [ 4  1  1  0  1  4  2  0  2 42  1  1  2  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0 62  0  0  0  0  0  0]\n",
      " [ 0  3  0  0  2  3  0  0  2  1  0 41  0  1  0  0  0]\n",
      " [ 0  1  3  0  0  1  0  0  0  1  1  0 59  0  1  0  1]\n",
      " [ 0  0  1  0  0  0  0  0  2  0  0  0  0 52  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 57  0  0]\n",
      " [ 3  1  2  0  0  1  0  0  0  0  0  3  0  0  0 53  0]\n",
      " [ 0  0  4  7  0  0  0  0  1  0  0  0  0  0  1  0 56]]\n"
     ]
    }
   ],
   "source": [
    "model=RandomForestClassifier()\n",
    "model.fit(x_train_scaled,y_train)\n",
    "y_pred=model.predict(x_test_scaled)\n",
    "\n",
    "print('accuracy ',accuracy_score(y_test,y_pred))\n",
    "print('classification_report\\n ',classification_report(y_test,y_pred))                            \n",
    "print('confusion_matrix\\n ',confusion_matrix(y_test,y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfe4016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bf56bc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(scaler,open('scaler.pkl','wb'))\n",
    "pickle.dump(model,open('model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "811f5625",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=pickle.load(open('scaler.pkl','rb'))\n",
    "model=pickle.load(open('model.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb28d3ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0ad3fbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "scaler=pickle.load(open('scaler.pkl','rb'))\n",
    "model=pickle.load(open('model.pkl','rb'))\n",
    "\n",
    "class_names=['Lawyer', 'Doctor', 'Government Officer', 'Artist', 'Unknown',\n",
    "       'Software Engineer', 'Teacher', 'Business Owner', 'Scientist',\n",
    "       'Banker', 'Writer', 'Accountant', 'Designer',\n",
    "       'Construction Engineer', 'Game Developer', 'Stock Investor',\n",
    "       'Real Estate Developer']\n",
    "\n",
    "def Recommendations(gender, part_time_job, absence_days, extracurricular_activities,\n",
    "                    weekly_self_study_hours, math_score, history_score, physics_score,\n",
    "                    chemistry_score, biology_score, english_score, geography_score,\n",
    "                    total_score,average_score):\n",
    "    \n",
    "    gender_encoded= 1 if gender.lower() == 'female' else 0\n",
    "    part_time_job_encoded= 1 if part_time_job else 0\n",
    "    extracurricular_activities_encoded= 1 if extracurricular_activities else 0\n",
    "    \n",
    "    feature_array = np.array([[gender_encoded, part_time_job_encoded, absence_days, extracurricular_activities_encoded,\n",
    "                               weekly_self_study_hours, math_score, history_score, physics_score,\n",
    "                               chemistry_score, biology_score, english_score, geography_score,total_score,\n",
    "                              average_score]])\n",
    "    \n",
    "    \n",
    "    scaled_features=scaler.transform(feature_array)\n",
    "    probabilities=model.predict_proba(scaled_features)\n",
    "    \n",
    "    top_classes_idx=np.argsort(-probabilities[0])[:5]\n",
    "    top_classes_names_probs=[(class_names[idx],probabilities[0][idx])for idx in top_classes_idx]\n",
    "    return top_classes_names_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "27382b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c852921a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommended studies with probabilities:\n",
      "==================================================\n",
      "Teacher with probability 0.5\n",
      "Business Owner with probability 0.18\n",
      "Unknown with probability 0.16\n",
      "Real Estate Developer with probability 0.08\n",
      "Government Officer with probability 0.05\n"
     ]
    }
   ],
   "source": [
    "final_recommendations = Recommendations(gender ='female',\n",
    "                                        part_time_job=False,\n",
    "                                        absence_days=2,\n",
    "                                        extracurricular_activities=False,\n",
    "                                        weekly_self_study_hours=7,\n",
    "                                        math_score=65,\n",
    "                                        history_score=60,\n",
    "                                        physics_score=97,\n",
    "                                        chemistry_score=94,\n",
    "                                        biology_score=71,\n",
    "                                        english_score=81,\n",
    "                                        geography_score=66,\n",
    "                                        total_score=534,\n",
    "                                        average_score=76.285714)\n",
    "\n",
    "print(\"Top recommended studies with probabilities:\")\n",
    "print(\"=\"*50)\n",
    "for class_name, probability in final_recommendations:\n",
    "    print(f\"{class_name} with probability {probability}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "be4bdb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the scaler, label encoder, model, and class names\n",
    "scaler = pickle.load(open(\"scaler.pkl\", 'rb'))\n",
    "model = pickle.load(open(\"model.pkl\", 'rb'))\n",
    "class_names = ['Lawyer', 'Doctor', 'Government Officer', 'Artist', 'Unknown',\n",
    "               'Software Engineer', 'Teacher', 'Business Owner', 'Scientist',\n",
    "               'Banker', 'Writer', 'Accountant', 'Designer',\n",
    "               'Construction Engineer', 'Game Developer', 'Stock Investor',\n",
    "               'Real Estate Developer']\n",
    "\n",
    "def Recommendations(gender, part_time_job, absence_days, extracurricular_activities,\n",
    "                    weekly_self_study_hours, math_score, history_score, physics_score,\n",
    "                    chemistry_score, biology_score, english_score, geography_score,\n",
    "                    total_score,average_score):\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    gender_encoded = 1 if gender.lower() == 'female' else 0\n",
    "    part_time_job_encoded = 1 if part_time_job else 0\n",
    "    extracurricular_activities_encoded = 1 if extracurricular_activities else 0\n",
    "    \n",
    "    # Create feature array\n",
    "    feature_array = np.array([[gender_encoded, part_time_job_encoded, absence_days, extracurricular_activities_encoded,\n",
    "                               weekly_self_study_hours, math_score, history_score, physics_score,\n",
    "                               chemistry_score, biology_score, english_score, geography_score,total_score,average_score]])\n",
    "    \n",
    "    # Scale features\n",
    "    scaled_features = scaler.transform(feature_array)\n",
    "    \n",
    "    # Predict using the model\n",
    "    probabilities = model.predict_proba(scaled_features)\n",
    "    \n",
    "    # Get top five predicted classes along with their probabilities\n",
    "    top_classes_idx = np.argsort(-probabilities[0])[:5]\n",
    "    top_classes_names_probs = [(class_names[idx], probabilities[0][idx]) for idx in top_classes_idx]\n",
    "    \n",
    "    return top_classes_names_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "732a0558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommended studies with probabilities:\n",
      "==================================================\n",
      "Teacher with probability 0.5\n",
      "Business Owner with probability 0.18\n",
      "Unknown with probability 0.16\n",
      "Real Estate Developer with probability 0.08\n",
      "Government Officer with probability 0.05\n"
     ]
    }
   ],
   "source": [
    "# Example usage 1\n",
    "final_recommendations = Recommendations(gender='female',\n",
    "                                        part_time_job=False,\n",
    "                                        absence_days=2,\n",
    "                                        extracurricular_activities=False,\n",
    "                                        weekly_self_study_hours=7,\n",
    "                                        math_score=65,\n",
    "                                        history_score=60,\n",
    "                                        physics_score=97,\n",
    "                                        chemistry_score=94,\n",
    "                                        biology_score=71,\n",
    "                                        english_score=81,\n",
    "                                        geography_score=66,\n",
    "                                        total_score=534,\n",
    "                                        average_score=76.285714)\n",
    "\n",
    "print(\"Top recommended studies with probabilities:\")\n",
    "print(\"=\"*50)\n",
    "for class_name, probability in final_recommendations:\n",
    "    print(f\"{class_name} with probability {probability}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "805d8426",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scikit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/58/_357jczx0g3b9nk13q16pf440000gn/T/ipykernel_34948/2868015689.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The scikit-learn version is {}.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscikit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'scikit' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450a0303",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
